{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Regularisation and Optimisation\n",
    "This assignment investigates training of CNNs on CIFAR with a goal of maximising accuracy.\n",
    "\n",
    "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) is a dataset with small size (32x32) images and 50k training samsamples.\n",
    "* It is often used as a \"Hello World\" type data set to setup a training pipeline. As it is relatively fast to train a network with CIFAR-10, this dataset is also widely used for running comparison or optimisation experiments. For example comparing different networks, regularisation methods or optimisers. (In pytorch the CIFAR-10 dataset is available as a [pytorch dataset](https://pytorch.org/vision/0.18/generated/torchvision.datasets.CIFAR10.html) simplifying loading the dataset.)\n",
    "\n",
    "The starting point in this assignment is an untrained convolutional neural network.\n",
    "* You will not modify the structure of the network. (We will discuss network structures in more detail in section 2 of module).\n",
    "* The network has sufficient capacity (Parameters/FLOPS) to achieve high accuracy.\n",
    "* The notebook (starting configurataion) will train the model without regularisation and using the SGD optimiser. From inspection of the training/validation accuracy/loss, it will be observed that the network is ovefitting.\n",
    "* You will improve the performance of the network using regularisation techniques (See below).\n",
    "* The goal is to use one or several techniques to prevent overfitting and maximse test accuracy.\n",
    "\n",
    "Regularisation techniques.\n",
    "* [Data Augmentation using pytorch transforms](https://pytorch.org/vision/0.15/transforms.html)\n",
    "* Regularisation layers such as [dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) and [batch normalisation](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html).\n",
    "\n",
    "The learning rate also acts as a regulariser, with large learning rates having a regularising effect. You may also include a LR schedule as detailed in the [pytorch optim package](https://pytorch.org/docs/stable/optim.html). The optim package contains several implementations of LR schedules including those detailed in the papers:\n",
    "* [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/pdf/1506.01186)\n",
    "* [Super-Convergence: Very Fast Training of Neural\n",
    "Networks Using Large Learning Rates](https://arxiv.org/pdf/1708.07120)\n",
    "\n",
    "\n",
    "How to approach this Assignment.\n",
    "* There are a lot things to try and possible approaches. Keep a table of what you have tried. Apart from recording training and test accuracy, Ensure that you record the key hyperparameters, including optimiser, base learning rate, number of epochs for each run. This makes repeating experiments possible if you want to try a variation.\n",
    "* Your final submitted notebook should include your best attempt showing training curves and a comment on your approach. (Do not submit a notebook with multiple approaches)\n"
   ],
   "metadata": {
    "id": "D0od727REF6w"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DEt0NrOfEBpA",
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:35.530270Z",
     "start_time": "2025-11-08T18:11:35.527338Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import ToTensor, v2, Pad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_"
   ],
   "outputs": [],
   "execution_count": 306
  },
  {
   "cell_type": "code",
   "source": "#!pip install torchinfo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Dx_DK31F4gR",
    "outputId": "0100deb6-dbd1-4a93-8d1a-bd9322b50cd6",
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:35.588623Z",
     "start_time": "2025-11-08T18:11:35.586727Z"
    }
   },
   "outputs": [],
   "execution_count": 307
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:35.594463Z",
     "start_time": "2025-11-08T18:11:35.592438Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install torchmetrics",
   "outputs": [],
   "execution_count": 308
  },
  {
   "cell_type": "code",
   "source": "#!pip install numpy",
   "metadata": {
    "id": "sRvOfG3jkN2o",
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:35.599534Z",
     "start_time": "2025-11-08T18:11:35.597391Z"
    }
   },
   "outputs": [],
   "execution_count": 309
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:35.605018Z",
     "start_time": "2025-11-08T18:11:35.602700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install tensorboard\n",
    "# url to see the data http://localhost:6006/?darkMode=true#timeseries"
   ],
   "outputs": [],
   "execution_count": 310
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:35.611793Z",
     "start_time": "2025-11-08T18:11:35.608679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if device == 'cuda':\n",
    "    # this part was added as I noticed with each run i would get a different result\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    print(\"CuDNN benchmark / deterministic mode ENABLED\") # since we have a fixed input of images may as well put the machine to work - faster convolution\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "CuDNN benchmark / deterministic mode ENABLED\n"
     ]
    }
   ],
   "execution_count": 311
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:35.620613Z",
     "start_time": "2025-11-08T18:11:35.615052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import autoaugment, InterpolationMode\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def fetch_accuracy(y_true, y_pred):\n",
    "\n",
    "    acc_A = accuracy_score(y_true, y_pred)\n",
    "    f1_macro_A = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(f\"Model A → Acc: {acc_A:.3f}, Macro-F1: {f1_macro_A:.3f}\")\n",
    "\n",
    "def fetch_train_object(batch_size, num_workers, pin_memory) :\n",
    "\n",
    "    train_transforms = v2.Compose([\n",
    "        v2.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.RandomErasing(p=0.25, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=0.0),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        ToTensor(),\n",
    "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    training_data = datasets.CIFAR10(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=train_transforms)\n",
    "\n",
    "    train_dataloader = DataLoader(training_data,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=num_workers,\n",
    "                                  pin_memory=pin_memory,\n",
    "                                  prefetch_factor=4,      # range 2- 8\n",
    "                                  persistent_workers=True)\n",
    "\n",
    "    print('Train Samples ',len(train_dataloader.dataset))\n",
    "    print('Train Batches ',len(train_dataloader))\n",
    "\n",
    "    return train_transforms, training_data, train_dataloader\n",
    "\n",
    "def fetch_test_object(batch_size, num_workers, pin_memory):\n",
    "\n",
    "    test_transforms = v2.Compose([\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        ToTensor(),\n",
    "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    test_data = datasets.CIFAR10(\n",
    "            root=\"data\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=test_transforms)\n",
    "\n",
    "    test_dataloader = DataLoader(test_data,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=num_workers,\n",
    "                                 pin_memory=pin_memory,\n",
    "                                 prefetch_factor=4,      # range 2- 8\n",
    "                                 persistent_workers=True)\n",
    "\n",
    "    print('Test Samples ',len(test_dataloader.dataset))\n",
    "    print('Test Batches ',len(test_dataloader))\n",
    "\n",
    "    return test_transforms, test_data, test_dataloader"
   ],
   "outputs": [],
   "execution_count": 312
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 128 # to speed up things  256\n",
    "num_workers = min(8, os.cpu_count() or 1)\n",
    "pin_memory = (device == 'cuda')\n",
    "\n",
    "train_transforms, training_data, train_dataloader = fetch_train_object(batch_size, num_workers, pin_memory)\n",
    "test_transforms, test_data, test_dataloader = fetch_test_object(batch_size, num_workers, pin_memory)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ],
   "metadata": {
    "id": "kj3lHLmyl-AR",
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:48.217098Z",
     "start_time": "2025-11-08T18:11:35.636360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples  50000\n",
      "Train Batches  391\n",
      "Test Samples  10000\n",
      "Test Batches  79\n",
      "Shape of X [N, C, H, W]: torch.Size([128, 3, 32, 32])\n",
      "Shape of y: torch.Size([128]) torch.int64\n"
     ]
    }
   ],
   "execution_count": 313
  },
  {
   "cell_type": "code",
   "source": [
    "#print('Test Samples ',len(test_dataloader.dataset))\n",
    "#print('Train Samples ',len(train_dataloader.dataset))\n",
    "#print('Test Batches ',len(test_dataloader))\n",
    "#print('Train Batches ',len(train_dataloader))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5iqVbNpQAOH",
    "outputId": "99f8e265-3c6c-4704-c476-48c0c6cdb658",
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:48.444917Z",
     "start_time": "2025-11-08T18:11:48.443520Z"
    }
   },
   "outputs": [],
   "execution_count": 314
  },
  {
   "cell_type": "code",
   "source": [
    "# Output next batch from dataloader\n",
    "#dataiter = iter(train_dataloader)\n",
    "#image_batch, labels_batch = next(dataiter)\n",
    "\n",
    "# Use matplotlib to plot a sample of images\n",
    "\n",
    "#i=0\n",
    "#n_plots = 12 # number of plots\n",
    "#f, axarr = plt.subplots(1,n_plots,figsize=(20,10))\n",
    "\n",
    "#for image in image_batch[0:n_plots,:,:,:]:\n",
    "#  disp_image =  torch.permute(image,(2,1,0)).numpy() # return image to cpu for display and permute to channels last\n",
    "#  mean = np.array([0.485, 0.456, 0.406])\n",
    "#  std = np.array([0.229, 0.224, 0.225])\n",
    "#  disp_image = std * disp_image + mean\n",
    "#  disp_image = np.clip(disp_image, 0, 1)\n",
    "#  axarr[i].imshow(disp_image[:,:,:])\n",
    "#  axarr[i].axis(\"off\")\n",
    "#  axarr[i].set_title(labels_batch[i].numpy(),fontsize='small')\n",
    "#  i = i+1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "L8VjVE0CmZYw",
    "outputId": "49dac2d6-d204-48fa-aefc-679bc97d641d",
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:48.451813Z",
     "start_time": "2025-11-08T18:11:48.447852Z"
    }
   },
   "outputs": [],
   "execution_count": 315
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define CNN Model\n",
    "\n",
    "To define a neural network in PyTorch, we create a class that inherits ([see python inheritance](https://www.w3schools.com/python/python_inheritance.asp))\n",
    "from\n",
    "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
    "We define the layers of the network in the `__init__` function and\n",
    "specify how data will pass through the network in the `forward`\n",
    "function. To accelerate operations in the neural network, we move it to\n",
    "the GPU.\n",
    "\n",
    "A simple CNN is defined using [2D convolution](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) and [2D max pooling layers](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html). [Relu activiation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) is applied after the convolution layers. The output of the last convolution is [flattened](https://pytorch.org/docs/stable/generated/torch.flatten.html) and [2 linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) (dense) layers applied. Only activiation is applied after the first linear layer. As seen in the next section when setting up our loss function we use the form `_from_logits` so the optimiser will know that softmax activiation needs to be applied. (Alternatively we can directly apply [softmax activiation](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html))\n",
    "\n",
    "* **You do not need to modify the network architecture**. You can add regularisation layers and adjust the optimisation/learning rate schedule which is a further method of regularisation in later code cells."
   ],
   "metadata": {
    "id": "TIIjqCm9IbxS"
   }
  },
  {
   "cell_type": "code",
   "source": "# -- model --",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCd2wpPqGW9n",
    "outputId": "3bce8d40-30bd-48c9-9abc-be664439f63c",
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:48.456989Z",
     "start_time": "2025-11-08T18:11:48.454129Z"
    }
   },
   "outputs": [],
   "execution_count": 316
  },
  {
   "cell_type": "code",
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.simple_cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding='same'),   # by having 2 conv we are looking for more features to extract\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),                            # convert negative to a 1\n",
    "            nn.Conv2d(32,64, 3, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # downsampling\n",
    "            #nn.Dropout(0.2),                         # on the QA videos you said it should not be added - but I noticed it keeps the gap between training and validation small\n",
    "\n",
    "            nn.Conv2d(64,64, 3, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64, 3, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # downsampling\n",
    "            #nn.Dropout(0.4),                        # on the QA videos you said it should not be added - but I noticed it keeps the gap between training and validation small\n",
    "\n",
    "            nn.Conv2d(64,128, 3, padding='same'),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128,256, 3, padding='same'),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256,256, 3, padding='same'),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2), # downsampling\n",
    "           # nn.Dropout(0.4),                        # on the QA videos you said it should not be added - but I noticed it keeps the gap between training and validation small\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1),                # replace the old ways of VGG with gold standard (brings parameters down from 5k to 1k) - did this before I went over the QA videos\n",
    "            nn.Flatten(),                           # classification\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),                        # trial and error - started with .2 and at .4 got the improvement ( same for the above )\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.simple_cnn(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "summary(model,\n",
    "        input_size=(1, 3, 32, 32),           # (batch, channels, H, W)\n",
    "        depth=4,\n",
    "        device=device\n",
    "    )"
   ],
   "metadata": {
    "id": "BUfqq6qqI4F4",
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:48.472947Z",
     "start_time": "2025-11-08T18:11:48.459036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork                            [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 10]                   --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 32, 32]           896\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 32, 32]           64\n",
       "│    └─ReLU: 2-3                         [1, 32, 32, 32]           --\n",
       "│    └─Conv2d: 2-4                       [1, 64, 32, 32]           18,496\n",
       "│    └─BatchNorm2d: 2-5                  [1, 64, 32, 32]           128\n",
       "│    └─ReLU: 2-6                         [1, 64, 32, 32]           --\n",
       "│    └─MaxPool2d: 2-7                    [1, 64, 16, 16]           --\n",
       "│    └─Conv2d: 2-8                       [1, 64, 16, 16]           36,928\n",
       "│    └─BatchNorm2d: 2-9                  [1, 64, 16, 16]           128\n",
       "│    └─ReLU: 2-10                        [1, 64, 16, 16]           --\n",
       "│    └─Conv2d: 2-11                      [1, 64, 16, 16]           36,928\n",
       "│    └─BatchNorm2d: 2-12                 [1, 64, 16, 16]           128\n",
       "│    └─ReLU: 2-13                        [1, 64, 16, 16]           --\n",
       "│    └─MaxPool2d: 2-14                   [1, 64, 8, 8]             --\n",
       "│    └─Conv2d: 2-15                      [1, 128, 8, 8]            73,856\n",
       "│    └─BatchNorm2d: 2-16                 [1, 128, 8, 8]            256\n",
       "│    └─ReLU: 2-17                        [1, 128, 8, 8]            --\n",
       "│    └─Conv2d: 2-18                      [1, 256, 8, 8]            295,168\n",
       "│    └─BatchNorm2d: 2-19                 [1, 256, 8, 8]            512\n",
       "│    └─ReLU: 2-20                        [1, 256, 8, 8]            --\n",
       "│    └─Conv2d: 2-21                      [1, 256, 8, 8]            590,080\n",
       "│    └─BatchNorm2d: 2-22                 [1, 256, 8, 8]            512\n",
       "│    └─MaxPool2d: 2-23                   [1, 256, 4, 4]            --\n",
       "│    └─AdaptiveAvgPool2d: 2-24           [1, 256, 1, 1]            --\n",
       "│    └─Flatten: 2-25                     [1, 256]                  --\n",
       "│    └─BatchNorm1d: 2-26                 [1, 256]                  512\n",
       "│    └─Dropout: 2-27                     [1, 256]                  --\n",
       "│    └─Linear: 2-28                      [1, 10]                   2,570\n",
       "==========================================================================================\n",
       "Total params: 1,057,162\n",
       "Trainable params: 1,057,162\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 100.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 2.75\n",
       "Params size (MB): 4.23\n",
       "Estimated Total Size (MB): 7.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 317
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimisation & Training Loop\n",
    "\n",
    "For this classification problem we will use the  [CrossEntropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). In this pytorch function, the input is the un-normalised logit value.\n",
    "\n",
    "* The SGD (Stocasitc Gradient Descent) Optimiser is provided as a the default training configuration. As the learning rate is fixed, this may not be optimal as training progresses for finding the global minimum.\n",
    "\n",
    "* Note that you can interrupt the training if it has converged (or failed) and then view the tensorboard curves and also obtain accuracy of the test set (by running the appropriate cells).\n",
    "\n",
    "* Make sure to run the model call and optimiser call before starting training again to ensure the previous training state is cleared.\n",
    "\n",
    "[Tensorboard is imported](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html) to display results.\n"
   ],
   "metadata": {
    "id": "Q3_9Lw9zOtNJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02,  weight_decay=1e-3, momentum=0.90, nesterov=False)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,          # new_lr = lr * factor\n",
    "    patience=10\n",
    ")"
   ],
   "metadata": {
    "id": "B3uYyCKb0VbQ",
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:48.479592Z",
     "start_time": "2025-11-08T18:11:48.477409Z"
    }
   },
   "outputs": [],
   "execution_count": 318
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Tensorboard (use of tensorboard in colab notebooks is [detailed here](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb))\n"
   ],
   "metadata": {
    "id": "r21Zjf3wx4Nt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "run_name = f\"exp_{int(time.time())}\"\n",
    "writer = SummaryWriter(log_dir=f\"runs/{run_name}\")"
   ],
   "metadata": {
    "id": "fd9d6fJIx7w1",
    "ExecuteTime": {
     "end_time": "2025-11-08T18:11:48.519509Z",
     "start_time": "2025-11-08T18:11:48.512812Z"
    }
   },
   "outputs": [],
   "execution_count": 319
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training & Validataion Loop"
   ],
   "metadata": {
    "id": "PRzXfw3K4P_L"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "n_iter =100   # Set how frequently will return loss (must be less than test_size)\n",
    "n_epochs = 30 # Set total number of epoochs\n",
    "\n",
    "train_size = len(train_dataloader.dataset)\n",
    "test_size = len(test_dataloader.dataset)\n",
    "num_test_batches = len(test_dataloader)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = running_acc = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "\n",
    "        # input and labels are pushed to the correct device\n",
    "        inputs, labels = [x.to(device) for x in data]\n",
    "\n",
    "        outputs = model(inputs)            # forward pass\n",
    "        loss = loss_fn(outputs, labels)    # compute loss\n",
    "\n",
    "        loss.backward()                    # compute gradient\n",
    "\n",
    "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()                   # update model based on gradient\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_acc += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "        if i % n_iter == n_iter-1:    # Every n mini-batches...\n",
    "\n",
    "            running_vloss = running_vacc = 0.0\n",
    "\n",
    "            model.eval()\n",
    "            for j, vdata in enumerate(test_dataloader, 0):\n",
    "\n",
    "                vinputs, vlabels = [x.to(device) for x in vdata]\n",
    "\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "\n",
    "                running_vloss += vloss.item()\n",
    "                running_vacc += (voutputs.argmax(1) == vlabels).type(torch.float).sum().item()\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            avg_loss = running_loss / n_iter                # Compute loss over n_iter iterations\n",
    "            avg_acc = 100*running_acc / (n_iter*batch_size) # number of examples computing accuracy over\n",
    "            avg_vloss = running_vloss / num_test_batches\n",
    "            avg_vacc = 100*running_vacc / test_size\n",
    "\n",
    "            scheduler.step(avg_vloss)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            global_step_index = epoch * len(train_dataloader) + i\n",
    "            writer.add_scalar('Learning Rate', current_lr, global_step_index)\n",
    "            writer.add_scalars('Loss',     {'Training Loss' : avg_loss, 'Validation Loss' : avg_vloss }, global_step_index)\n",
    "            print(f\"\\nStep {global_step_index:03d} — Gap (train-val): {avg_loss-avg_vloss:.4f}\")\n",
    "            writer.add_scalars('Accuracy', {'Training Acc'  : avg_acc, 'Validation Acc'   : avg_vacc  }, global_step_index)\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SwABO9ylyP0E",
    "outputId": "251026b2-287d-4d43-f715-94d82fc626dd",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-08T18:11:48.522094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 099 — Gap (train-val): 0.0360\n",
      "\n",
      "Step 199 — Gap (train-val): -0.4674\n",
      "\n",
      "Step 299 — Gap (train-val): -0.0486\n",
      "\n",
      "Step 490 — Gap (train-val): -0.0362\n",
      "\n",
      "Step 590 — Gap (train-val): 0.0120\n",
      "\n",
      "Step 690 — Gap (train-val): -0.3541\n",
      "\n",
      "Step 881 — Gap (train-val): -0.0895\n",
      "\n",
      "Step 981 — Gap (train-val): 0.0306\n",
      "\n",
      "Step 1081 — Gap (train-val): -0.0012\n",
      "\n",
      "Step 1272 — Gap (train-val): -0.0724\n",
      "\n",
      "Step 1372 — Gap (train-val): -0.1514\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Model\n",
    "We will obtain the classification report after final evaluation of the test dataset with the model. A confusion matrix can also be obtained and we will plot a few example images."
   ],
   "metadata": {
    "id": "c14uQnBWqjfp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "store_predictions = []\n",
    "store_labels = []\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    # basic training loop\n",
    "    input_batch, label_batch = data\n",
    "    input_batch = input_batch.to(device)\n",
    "\n",
    "    pred_logit = model(input_batch)\n",
    "    predictions = torch.argmax(pred_logit,1) # reduce along output dimension\n",
    "    predictions_np = predictions.to(\"cpu\").numpy()\n",
    "    label_batch_np = label_batch.numpy()\n",
    "    if i<num_test_batches-1:\n",
    "      store_predictions.append(predictions_np)\n",
    "      store_labels.append(label_batch)\n",
    "\n",
    "y_pred = np.squeeze(np.reshape(store_predictions,(1,(num_test_batches-1)*batch_size)))\n",
    "y_true = np.squeeze(np.reshape(store_labels,(1,(num_test_batches-1)*batch_size)))"
   ],
   "metadata": {
    "id": "m1p_BCQGqk0B"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "fetch_accuracy(y_true, y_pred)\n",
    "plot_confusion_matrix(confusion_matrix(y_true, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpx7edXcqtUB",
    "outputId": "94650bbb-3d81-48b8-a911-3b2fd8814a14"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#%tensorboard --logdir=runs --port=6006 --bind_all",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Output next batch from dataloader\n",
    "dataiter = iter(test_dataloader)\n",
    "image_batch, labels_batch = next(dataiter)\n",
    "\n",
    "# Pass batch through model\n",
    "model.eval()\n",
    "image_batch = image_batch.to(device)\n",
    "pred_logit = model(image_batch)\n",
    "\n",
    "\n",
    "# Use matplotlib to plot a sample of images\n",
    "import matplotlib.pyplot as plt\n",
    "i=0\n",
    "n_plots = 12 # number of plots\n",
    "f, axarr = plt.subplots(1,n_plots,figsize=(20,10))\n",
    "\n",
    "\n",
    "for image in image_batch[0:n_plots,:,:,:]:\n",
    "  disp_image =  torch.permute(image.to('cpu'),(2,1,0)).numpy() # return image to cpu for display and permute to channels last\n",
    "  mean = np.array([0.485, 0.456, 0.406])\n",
    "  std = np.array([0.229, 0.224, 0.225])\n",
    "  disp_image = std * disp_image + mean\n",
    "  disp_image = np.clip(disp_image, 0, 1)\n",
    "  axarr[i].imshow(disp_image[:,:,:])\n",
    "  axarr[i].axis(\"off\")\n",
    "  predicted, actual = classes[pred_logit[i,:].argmax(0)], classes[labels_batch[i]]\n",
    "  color = 'black' if predicted == actual else 'red'\n",
    "  axarr[i].set_title(predicted,fontsize='small', color=color)\n",
    "  i = i+1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "hp6WRpYQqtyi",
    "outputId": "dd531bef-a6c6-4104-ed9c-d7cd94433021"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Comments about your Approach"
   ],
   "metadata": {
    "id": "NO3wWuZk4VRm"
   }
  }
 ]
}
