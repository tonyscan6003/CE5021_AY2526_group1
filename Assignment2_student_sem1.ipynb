{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer Learning with Med MNIST.\n",
        "\n",
        "In this assignment you will use transfer learning to train a model of your choice on a sub-dataset from the [MedMNIST datasets](https://medmnist.com/). ![](https://github.com/tonyscan6003/etivities/blob/main/medmnist.JPG?raw=true)\n",
        "\n",
        "* The [MedMNIST package](https://github.com/MedMNIST/MedMNIST/blob/main/examples/getting_started.ipynb) allows the data to be imported directly as a pytorch dataset.\n",
        "\n",
        "* You may select any of the datasets using Multi-class/binary classification. The goal is to acheve accuracy levels comparable to the benchmark results shown on the medmnist site. Dataloading for pytorch is setup in the notebook, you wil need to modify the code slightly depending on your dataset of choice.\n",
        "\n",
        "* Some datasets use black and white images, so you will need to [at least concatenate](https://towardsdatascience.com/transfer-learning-on-greyscale-images-how-to-fine-tune-pretrained-models-on-black-and-white-9a5150755c7a) the input image channels (to 3 channels) for compatibility with the models pre-trained on imageNet.\n",
        "\n",
        "* Some of the MedMNIST datasets don't contain too much data so Data augmentation may be essentila essential to avoid overfitting. In pytorch data augmentation is performed using the [transforms.v2](https://pytorch.org/vision/main/transforms.html) modules.\n",
        "\n",
        "* In this notebook: You will need to import a model, and perform training. Tranfer Learning for computer vision is detailed [here](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
        "\n",
        "* [Tensorboard can be imported](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html) to display results.\n",
        "\n",
        "* Please only include one example of transfer learning in the submitted notebook. Making sure training curves/results are clearly visible. If you have trained additional transfer learning models (i.e. that were less successful) please add this as a table or report at the end of the notebook and/or in your final forum post.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D0od727REF6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install & Import Packages"
      ],
      "metadata": {
        "id": "02jbObyemiYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist\n",
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "ALnzL_qv0J9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEt0NrOfEBpA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, models\n",
        "from torchvision.transforms import ToTensor, v2, Pad, Grayscale\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setup & Import Dataset\n",
        "The [MedMNSIT](https://medmnist.com/) package (imported above) makes available several medical datasets available to access.\n",
        "\n",
        "You can change the `data_flag` variable (dataset names are all lower case letters) to the dataset of your choice (Take care to note the parameters e.g. number of input channels below that will affect your model)\n",
        "\n"
      ],
      "metadata": {
        "id": "S65n7FefE5T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "data_flag = 'bloodmnist'\n",
        "#data_flag = 'pathmnist'\n",
        "download = True\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "print('Type of Machine Learning Task = ',task)\n",
        "print('Number of Input Data Channels = ',n_channels)\n",
        "print('Number of Classes = ',n_classes)\n",
        "print('The batch size for this dataset will be = ',BATCH_SIZE)\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ],
      "metadata": {
        "id": "caFqq_2T5uaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms:\n",
        "You can update the functions below with appropriate transforms for your particular use case.\n",
        "\n",
        "* As well as being suitable for data augmention for image classification, the transforms.v2 package of torchvision extends transforms for object detection and segmentation tasks. An illustration of the transforms is shown [here](https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py).\n",
        "* Normalisation based on ImageNet parameters is included already. This should be used with all models pre-trained on ImageNet  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yEcCkv14yJzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_transforms = v2.Compose([\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "test_transforms = v2.Compose([\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "lj7Ag9F9hBqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup your Medmnist dataset.\n",
        "* The convolution part of pre-trained networks (such as resnet) are compatable with any size input image. However they were trained on 224 x 224 size images, with early layers finding small scale features and deeper layers finding large scale features.\n",
        "* For this transfer learning application to medical data, the gap between the original ImageNet domain and the medical images is wide. Therefore the size/scale of the input images is less important, however in general we would expect better performance with the larger input images (as they contain more features at different scales).\n",
        "* You can add the `size=224` parameter to the dataset object calls, to load full size images. Only do this once you are confident in your training methodology (or if the dataset is small), as training with full size images will take longer.\n"
      ],
      "metadata": {
        "id": "daS_Z6OayI3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "train_dataset = DataClass(split='train', transform=train_transforms, download=download, size=224, mmap_mode='r')\n",
        "test_dataset = DataClass(split='test', transform=test_transforms, download=download, size=224, mmap_mode='r')\n",
        "val_dataset = DataClass(split='val', transform=test_transforms, download=download, size=224, mmap_mode='r')\n",
        "#train_dataset = DataClass(split='train', transform=train_transforms, download=download, mmap_mode='r')\n",
        "#test_dataset = DataClass(split='test', transform=test_transforms, download=download, mmap_mode='r')\n",
        "#val_dataset = DataClass(split='val', transform=test_transforms, download=download, mmap_mode='r')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CGcCuvXjE7TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Dataset` is passed as an argument to `DataLoader`. This wraps an\n",
        "iterable over the dataset, and supports automatic batching, sampling,\n",
        "shuffling and multiprocess data loading."
      ],
      "metadata": {
        "id": "LH_kTIFYIoTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "bX-snmo0Iv3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot some example augmented images"
      ],
      "metadata": {
        "id": "Nr4srFL0ZDU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output next batch from dataloader\n",
        "dataiter = iter(train_dataloader)\n",
        "image_batch, labels_batch = next(dataiter)\n",
        "\n",
        "# Use matplotlib to plot a sample of images\n",
        "\n",
        "i=0\n",
        "n_plots = 12 # number of plots\n",
        "f, axarr = plt.subplots(1,n_plots,figsize=(20,10))\n",
        "\n",
        "for image in image_batch[0:n_plots,:,:,:]:\n",
        "  disp_image =  torch.permute(image,(2,1,0)).numpy() # return image to cpu for display and permute to channels last\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  disp_image = std * disp_image + mean\n",
        "  disp_image = np.clip(disp_image, 0, 1)\n",
        "  axarr[i].imshow(disp_image[:,:,:])\n",
        "  axarr[i].axis(\"off\")\n",
        "  axarr[i].set_title(labels_batch[i].numpy(),fontsize='small')\n",
        "  i = i+1\n"
      ],
      "metadata": {
        "id": "Ofqjq8b4ZIJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Define Transfer Learning model\n",
        "Pytorch has an inbuilt [models package](https://pytorch.org/vision/stable/models.html) that allows loading of popular models with pre-trained weights.\n",
        "\n",
        "* We want to add an additional classifier stage (to the output of the network). How to setup the [model is detailed here](https://discuss.pytorch.org/t/load-only-a-part-of-the-network-with-pretrained-weights/88397/2).\n",
        "* This additional classifier may just be a single layer or a cascade of fully connected layers with dropout.\n",
        "* Note that the number of parameters in the convolutional part of the model will be same no what the input size is set to. However the output feature map size will vary with input image size (small for small image, large for large image). This means the number of parameters in the additional classifier will change depending on input image size.\n"
      ],
      "metadata": {
        "id": "TIIjqCm9IbxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "yZ1W5n704brZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(train_dataset)\n",
        "#print(\"===================\")\n",
        "#print(test_dataset)\n",
        "\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "pretrained_model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, my_pretrained_model):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.backbone = nn.Sequential(*list(my_pretrained_model.children())[:-1])\n",
        "        self.fc = nn.Sequential(nn.Linear(512, 128),\n",
        "                                          nn.ReLU(),\n",
        "                                          nn.Dropout(0.4),\n",
        "                                          nn.Linear(128, 9))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "my_extended_model = MyModel(my_pretrained_model=pretrained_model).to(device)\n",
        "\n",
        "my_extended_model\n"
      ],
      "metadata": {
        "id": "eAowJMuY23l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Optimisation & Training Loop\n",
        "\n",
        "Define a training loop that prints the loss from the training and validation set at least every epoch.\n",
        "* You may choose to make the validation loss calculations more frequent so you can ensure training is progressing satisfactorily (especially with larger datasets).\n",
        "\n",
        "* You can use tensorboard to visualise the [loss curves](https://pytorch.org/docs/stable/tensorboard.html))\n",
        "\n",
        "* For multi-class classification classification problem we will use the  [CrossEntropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). In this pytorch function, the input is the un-normalised logit value.\n",
        "\n",
        "* You may  have to use [torch.squeeze](https://pytorch.org/docs/stable/generated/torch.squeeze.html) to reduce the dimensionality of the label tensor before passing it to the loss function (this due to how the dataset is configured and the loss will only accept 0D or 1D inputs)"
      ],
      "metadata": {
        "id": "Q3_9Lw9zOtNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8M2JtkKg7xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(my_extended_model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "id": "B3uYyCKb0VbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs=20\n",
        "n_iter =100\n",
        "\n",
        "# Define these variables before the loop\n",
        "num_test_batches = len(test_dataloader)\n",
        "test_size = len(test_dataset) # Assuming test_dataset is used for validation based on current code\n",
        "\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    my_extended_model.train() # Ensure model is in training mode at the start of each epoch\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # basic training loop\n",
        "        inputs, labels = data\n",
        "        labels = labels.squeeze()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = my_extended_model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
        "        if i % n_iter == n_iter-1:    # Every n mini-batches...\n",
        "            print('Epoch {}'.format(epoch),' Batch {}'.format(i + 1))\n",
        "            # Check against the validation set\n",
        "            running_vloss = 0.0\n",
        "            running_vacc = 0.0\n",
        "            # In evaluation mode some model specific operations can be omitted eg. dropout layer\n",
        "            my_extended_model.eval() # Switching to evaluation mode, eg. turning off regularisation\n",
        "            with torch.no_grad(): # Disable gradient calculation for validation\n",
        "                for j, vdata in enumerate(test_dataloader, 0):\n",
        "\n",
        "                    vinputs, vlabels = vdata\n",
        "                    vlabels = vlabels.squeeze() # Apply squeeze to validation labels too\n",
        "                    vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
        "                    voutputs = my_extended_model(vinputs)\n",
        "                    vloss = loss_fn(voutputs, vlabels)\n",
        "                    running_vloss += vloss.item()\n",
        "                    running_vacc += (voutputs.argmax(1) == vlabels).type(torch.float).sum().item()\n",
        "            my_extended_model.train() # Switching back to training mode, eg. turning on regularisation\n",
        "\n",
        "            avg_loss = running_loss / n_iter  # Compute loss over n_iter iterations\n",
        "            avg_acc = 100*running_acc / (n_iter*BATCH_SIZE) # number of examples computing accuracy over\n",
        "            avg_vloss = running_vloss / num_test_batches\n",
        "            avg_vacc = 100*running_vacc / test_size\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "            # Print intermediate results\n",
        "            print(f\"Training Error: \\n Accuracy: {(avg_acc):>0.1f}%, Avg loss: {avg_loss:>8f} \\n\")\n",
        "            print(f\"Test Error: \\n Accuracy: {(avg_vacc):>0.1f}%, Avg loss: {avg_vloss:>8f} \\n\")\n",
        "\n",
        "            # Log the running loss averaged per batch\n",
        "            writer.add_scalars('Loss',\n",
        "                            { 'Training Loss' : avg_loss, 'Validation Loss' : avg_vloss },\n",
        "                            epoch * len(train_dataloader) + i)\n",
        "            writer.add_scalars('Accuracy',\n",
        "                            {'Training Acc' : avg_acc, 'Validation Acc' : avg_vacc },\n",
        "                            epoch * len(train_dataloader) + i)\n",
        "\n",
        "    scheduler.step()\n",
        "writer.flush()\n",
        "print('Finished Training')\n",
        "\n"
      ],
      "metadata": {
        "id": "JZ-Rt97RZXu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialise Tensorboard (use of tensorboard in colab notebooks is [detailed here](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb)). A [Pytorch tutorial](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html) shows how to setup the training and validation loop with pytorch.\n"
      ],
      "metadata": {
        "id": "r21Zjf3wx4Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3_qufsvrzTUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir runs --bind_all"
      ],
      "metadata": {
        "id": "CWWFZg3mPLU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter('runs')"
      ],
      "metadata": {
        "id": "fd9d6fJIx7w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Evaluate Model\n",
        "You will need to setup an evaluation loop for the model to assess it's performance on the test dataset.\n",
        "\n",
        "You may also obtain a classification report after final evaluation of the test dataset with the model using the code below. A confusion matrix can also be obtained and we will plot a few example images.\n",
        "\n"
      ],
      "metadata": {
        "id": "T3KEd881eG-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://scikit-learn.org/0.16/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "plot_confusion_matrix(cm)"
      ],
      "metadata": {
        "id": "4jbe4FkwkEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred, target_names=classes))"
      ],
      "metadata": {
        "id": "RN2167c_kKRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Comments about your Approach"
      ],
      "metadata": {
        "id": "zkZQ0yQS4JTL"
      }
    }
  ]
}